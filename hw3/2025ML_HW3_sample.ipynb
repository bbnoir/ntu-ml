{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opTIkC9Ct_YS"
   },
   "source": [
    "# ML HW3 Sample Code\n",
    "TODO:\n",
    " - Design your AutoEncoder model\n",
    " - Pre-train with unlabelled data\n",
    "    - Augmentation\n",
    " - Fine-tune with labelled data\n",
    "    - Augmentation\n",
    "    - Loss function\n",
    "\n",
    "Report:\n",
    " - Clustering\n",
    "    - Implement Equilibrium K-means algorithm\n",
    "    - t-SNE : Show the embedding of different classes\n",
    " - Anomaly detection\n",
    "    - Reconstruct unseen classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iun98ffpt_YW"
   },
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OA-FU0ZkuOov"
   },
   "outputs": [],
   "source": [
    "# !gdown 1Bw1ksB6AkTICynIHHkG7NKAdf3sBI1uR\n",
    "# !gdown 1kO12YQxqGFLbY3WiskJyYG7S-hiPae24\n",
    "# !unzip -q 'hw3.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLz0hckrt_YX"
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8nGkJNjLt_YX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision as tv\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from argparse import Namespace\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UoqTwBLpt_YZ"
   },
   "source": [
    "## Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6nMN8TwRt_Ya"
   },
   "outputs": [],
   "source": [
    "def load_unlabelled(img_dir):\n",
    "    return  [ Image.open(os.path.join(img_dir, str(i)+'.jpg')) for i in range(len(os.listdir(img_dir))) ]\n",
    "\n",
    "\n",
    "def load_labelled(root_dir):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for label in os.listdir(root_dir):\n",
    "        for img in os.listdir(os.path.join(root_dir, label)):\n",
    "            img = Image.open(os.path.join(root_dir, label, img))\n",
    "            data.append(img)\n",
    "            labels.append(int(label))\n",
    "    return [*zip(data, labels)]\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, imgs, labels=None, tfm=T.ToTensor()):\n",
    "        super().__init__()\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "        self.tfm = tfm\n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels is None:\n",
    "            return self.tfm(self.imgs[idx])\n",
    "            # return nn.AvgPool2d(2,2)(self.tfm(self.imgs[idx]))\n",
    "        else:\n",
    "            return self.tfm(self.imgs[idx]), self.labels[idx]\n",
    "            # return nn.AvgPool2d(2,2)(self.tfm(self.imgs[idx])), self.labels[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHoRIe0st_Yb"
   },
   "source": [
    "## AutoEncoder model\n",
    "<span style=\"color:orange\">(TODO: Design your model)</span>\n",
    "\n",
    "<img src=\"https://julien-vitay.net/lecturenotes-neurocomputing/_images/semisupervised-autoencoder.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CMJhlLnt_Yc"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement your autoencoder model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(start_dim=1),   # Flatten to feed into the linear layer\n",
    "            nn.Linear(512*4*4, 1024)\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(1024, 512*4*4),\n",
    "            nn.Unflatten(dim=1, unflattened_size=(512, 4, 4)),   # Unflatten\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid()  # Use sigmoid to get pixel values between 0 and 1\n",
    "        )\n",
    "\n",
    "        # classifier head\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(1024, 1024),   # Latent space with 1024 features\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encode\n",
    "        z = self.encoder(x)\n",
    "        # decode\n",
    "        x_prime = self.decoder(z)\n",
    "        # classify\n",
    "        y = self.predictor(z)\n",
    "        return x_prime, y, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SMmDifFt_Yd"
   },
   "source": [
    "## Pre-train with unlabelled data\n",
    "<span style=\"color:orange\">(TODO: Hyperparameter tuning / Augmentation)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y9Y3_FbFt_Yd"
   },
   "outputs": [],
   "source": [
    "def add_noise(x, noise_factor=0.1):\n",
    "    if noise_factor <= 0:\n",
    "        return x\n",
    "    noise = noise_factor * torch.randn_like(x)\n",
    "    return torch.clamp(x + noise, 0.0, 1.0)\n",
    "\n",
    "def pretrain(model, train_loader, valid_loader, config, noise_function=add_noise):\n",
    "    model = model.to(config.device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "    max_grad_norm = getattr(config, 'max_grad_norm', None)\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    for epoch in range(config.pretrain_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        progress = tqdm(train_loader, desc=f'Pretrain {epoch + 1}/{config.pretrain_epochs}', leave=False)\n",
    "        for img in progress:\n",
    "            img = img.to(config.device, non_blocking=True)\n",
    "            noisy_img = noise_function(img, getattr(config, 'noise_factor', 0.0))\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            x_prime, _, _ = model(noisy_img)\n",
    "            loss = criterion(x_prime, img)\n",
    "\n",
    "            loss.backward()\n",
    "            if max_grad_norm is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            progress.set_postfix({'loss': loss.item()})\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        if valid_loader is not None:\n",
    "            model.eval()\n",
    "            valid_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for img in valid_loader:\n",
    "                    img = img.to(config.device, non_blocking=True)\n",
    "                    x_prime, _, _ = model(img)\n",
    "                    loss = criterion(x_prime, img)\n",
    "                    valid_loss += loss.item()\n",
    "            valid_loss /= len(valid_loader)\n",
    "            valid_losses.append(valid_loss)\n",
    "\n",
    "            scheduler.step(valid_loss)\n",
    "\n",
    "            if valid_loss < best_valid_loss:\n",
    "                best_valid_loss = valid_loss\n",
    "                torch.save(model.state_dict(), config.pretrain_model_path)\n",
    "\n",
    "            print(f'Epoch {epoch + 1}/{config.pretrain_epochs}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}')\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, config.pretrain_epochs + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, config.pretrain_epochs + 1), valid_losses, label='Valid Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqi6ZV_Pt_Ye"
   },
   "outputs": [],
   "source": [
    "pretrain_train_tfm = T.Compose([\n",
    "    T.RandomResizedCrop(64, scale=(0.65, 1.0)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomApply([\n",
    "        T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1)\n",
    "    ], p=0.8),\n",
    "    T.RandomGrayscale(p=0.1),\n",
    "    T.RandomApply([T.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0))], p=0.2),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "pretrain_valid_tfm = T.Compose([\n",
    "    T.Resize(72),\n",
    "    T.CenterCrop(64),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "use_augmentation = True\n",
    "if not use_augmentation:\n",
    "    pretrain_train_tfm = T.ToTensor()\n",
    "    pretrain_valid_tfm = T.ToTensor()\n",
    "\n",
    "pretrain_config = Namespace(\n",
    "    batch_size = 128,\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    lr = 5e-4,\n",
    "    weight_decay = 1e-5,\n",
    "    noise_factor = 0.05,\n",
    "    pretrain_epochs = 30,\n",
    "    max_grad_norm = 1.0,\n",
    "    pretrain_model_path = 'pretrain_model.ckpt'\n",
    ")\n",
    "\n",
    "print('Device:', pretrain_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yqLj0dxbt_Yf"
   },
   "outputs": [],
   "source": [
    "pretrain_train_data = load_unlabelled('/docker_data/ysyang/ml/data/dev/unlabelled')\n",
    "pretrain_train_data, pretrain_valid_data = torch.utils.data.random_split(pretrain_train_data, [0.8, 0.2])\n",
    "pretrain_train_dataset = ImageDataset(pretrain_train_data, tfm=pretrain_train_tfm)\n",
    "pretrain_valid_dataset = ImageDataset(pretrain_valid_data, tfm=pretrain_valid_tfm)\n",
    "\n",
    "num_workers = min(4, os.cpu_count() or 1)\n",
    "pin_memory = torch.cuda.is_available()\n",
    "\n",
    "pretrain_train_loader = DataLoader(\n",
    "    pretrain_train_dataset,\n",
    "    batch_size=pretrain_config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "pretrain_valid_loader = DataLoader(\n",
    "    pretrain_valid_dataset,\n",
    "    batch_size=pretrain_config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AUsIEMwet_Yg"
   },
   "outputs": [],
   "source": [
    "model = Autoencoder()\n",
    "pretrain(model, pretrain_train_loader, pretrain_valid_loader, pretrain_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PAGum3Rt_Yg"
   },
   "source": [
    "## Fine-tune with labelled data\n",
    "<span style=\"color:orange\">(TODO: Loss function / Augmentation)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RGyNU-17t_Yh"
   },
   "outputs": [],
   "source": [
    "def loss_fn(x_prime, y, z, x, y_hat):\n",
    "    # TODO: Define your loss function for fine-tuning\n",
    "    # You might want to consider the reconstruction loss and/or the classification loss\n",
    "    reconstruction_loss = nn.MSELoss()(x_prime, x)\n",
    "    classification_loss = nn.CrossEntropyLoss()(y, y_hat)\n",
    "    weight_reconstruction = 0.15\n",
    "    return weight_reconstruction * reconstruction_loss + (1 - weight_reconstruction) * classification_loss\n",
    "\n",
    "def finetune(model, train_loader, valid_loader, config, noise_function=add_noise):\n",
    "    model = model.to(config.device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "    max_grad_norm = getattr(config, 'max_grad_norm', None)\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    best_valid_acc = 0.0\n",
    "\n",
    "    for epoch in range(config.finetune_epochs):\n",
    "        model.train()\n",
    "        train_loss, train_acc = 0.0, 0.0\n",
    "        progress = tqdm(train_loader, desc=f'Finetune {epoch + 1}/{config.finetune_epochs}', leave=False)\n",
    "        for img, label in progress:\n",
    "            img = img.to(config.device, non_blocking=True)\n",
    "            label = label.to(config.device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            output = model(img)\n",
    "            loss = loss_fn(*output, img, label)\n",
    "            loss.backward()\n",
    "            if max_grad_norm is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "            preds = output[1].argmax(dim=1)\n",
    "            batch_acc = (preds == label).float().mean().item()\n",
    "            train_loss += loss.item()\n",
    "            train_acc += batch_acc\n",
    "            progress.set_postfix({'loss': loss.item(), 'acc': batch_acc})\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc /= len(train_loader)\n",
    "        print(f'Epoch {epoch + 1}/{config.finetune_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss, valid_acc = 0.0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for img, label in valid_loader:\n",
    "                img = img.to(config.device, non_blocking=True)\n",
    "                label = label.to(config.device, non_blocking=True)\n",
    "                output = model(img)\n",
    "                loss = loss_fn(*output, img, label)\n",
    "                valid_loss += loss.item()\n",
    "                valid_acc += (output[1].argmax(dim=1) == label).float().mean().item()\n",
    "\n",
    "        valid_loss /= len(valid_loader)\n",
    "        valid_acc /= len(valid_loader)\n",
    "        scheduler.step(valid_loss)\n",
    "\n",
    "        if valid_acc > best_valid_acc:\n",
    "            best_valid_acc = valid_acc\n",
    "            torch.save(model.state_dict(), config.finetune_model_path)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{config.finetune_epochs}, Valid Loss: {valid_loss:.4f}, Valid Acc: {valid_acc:.4f}')\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, config.finetune_epochs + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, config.finetune_epochs + 1), valid_losses, label='Valid Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Oi3l0T7t_Yh"
   },
   "outputs": [],
   "source": [
    "finetune_train_tfm = T.Compose([\n",
    "    T.RandomResizedCrop(64, scale=(0.65, 1.0)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomApply([\n",
    "        T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1)\n",
    "    ], p=0.7),\n",
    "    T.RandomGrayscale(p=0.1),\n",
    "    T.RandomApply([T.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0))], p=0.2),\n",
    "    T.ToTensor(),\n",
    "    T.RandomErasing(p=0.2, scale=(0.02, 0.15), ratio=(0.3, 3.3)),\n",
    "])\n",
    "finetune_valid_tfm = T.Compose([\n",
    "    T.Resize(72),\n",
    "    T.CenterCrop(64),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "if not use_augmentation:\n",
    "    finetune_train_tfm = T.ToTensor()\n",
    "    finetune_valid_tfm = T.ToTensor()\n",
    "\n",
    "finetune_config = Namespace(\n",
    "    batch_size = 32,\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    lr = 3e-4,\n",
    "    weight_decay = 1e-4,\n",
    "    noise_factor = 0.02,\n",
    "    finetune_epochs = 60,\n",
    "    max_grad_norm = 1.0,\n",
    "    reconstruction_weight = 0.15,\n",
    "    label_smoothing = 0.05,\n",
    "    latent_reg_weight = 1e-4,\n",
    "    finetune_model_path = 'finetune_model.ckpt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iLZDx8G4t_Yi"
   },
   "outputs": [],
   "source": [
    "finetune_train_data = load_labelled('/docker_data/ysyang/ml/data/dev/labelled')\n",
    "finetune_train_data, finetune_valid_data = torch.utils.data.random_split(finetune_train_data, [0.8, 0.2])\n",
    "finetune_train_dataset = ImageDataset(*map(list, zip(*finetune_train_data)), finetune_train_tfm)\n",
    "finetune_valid_dataset = ImageDataset(*map(list, zip(*finetune_valid_data)), finetune_valid_tfm)\n",
    "\n",
    "num_workers = min(4, os.cpu_count() or 1)\n",
    "pin_memory = torch.cuda.is_available()\n",
    "\n",
    "finetune_train_loader = DataLoader(\n",
    "    finetune_train_dataset,\n",
    "    batch_size=finetune_config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "finetune_valid_loader = DataLoader(\n",
    "    finetune_valid_dataset,\n",
    "    batch_size=finetune_config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gk-e9b0lt_Yi"
   },
   "outputs": [],
   "source": [
    "model = Autoencoder()\n",
    "model.load_state_dict(torch.load(pretrain_config.pretrain_model_path))\n",
    "finetune(model, finetune_train_loader, finetune_valid_loader, finetune_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKCNR59Qt_Yi"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pmop57x0t_Yi"
   },
   "outputs": [],
   "source": [
    "test_dataset = ImageDataset(sorted(load_unlabelled('/docker_data/ysyang/ml/data/test'), key=lambda x: int(x.filename.split('/')[-1].split('.')[0])))\n",
    "test_loader = DataLoader(test_dataset, batch_size=finetune_config.batch_size, shuffle=False)\n",
    "\n",
    "model = Autoencoder()\n",
    "model.load_state_dict(torch.load('finetune_model.ckpt'))\n",
    "model = model.to(finetune_config.device).eval()\n",
    "\n",
    "# Generate predictions\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for img in test_loader:\n",
    "        img = img.to(finetune_config.device)\n",
    "        _, y, _ = model(img)\n",
    "        predictions.append(y.argmax(dim=1).cpu().numpy())\n",
    "predictions = np.concatenate(predictions)\n",
    "\n",
    "# Save predictions\n",
    "with open('predict.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['id', 'label'])\n",
    "    for id, r in enumerate(predictions):\n",
    "        writer.writerow([id, r])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5tSbWbrt_Yj"
   },
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXF_l0sot_Yk"
   },
   "source": [
    "### Clustering\n",
    "<span style=\"color:orange\">(TODO: Implement the Equilibrium K-means algorithm)</span>\n",
    "ref: https://arxiv.org/pdf/2402.14490\n",
    "\n",
    "Distance between a data point $x_n$ and centroid $c_k$\n",
    "$$d_{ik} = \\frac{1}{2} \\| x_i - c_k \\|^2$$\n",
    "\n",
    "Equation 38: Weight calculation\n",
    "$$w_{kn}^{(\\tau)} = \\frac{e^{-\\alpha d_{kn}^{(\\tau)}}}{\\sum_{i=1}^K e^{-\\alpha d_{in}^{(\\tau)}}}\n",
    "\\left[ 1 - \\alpha \\left( d_{kn}^{(\\tau)} -\n",
    "\\frac{\\sum_{i=1}^K d_{in}^{(\\tau)} e^{-\\alpha d_{in}^{(\\tau)}}}{\\sum_{i=1}^K e^{-\\alpha d_{in}^{(\\tau)}}}\n",
    "\\right) \\right]$$\n",
    "\n",
    "Equation 39: Centroid update\n",
    "$$c_k^{(\\tau+1)} = \\frac{\\sum_{n=1}^N w_{kn}^{(\\tau)} x_n}{\\sum_{n=1}^N w_{kn}^{(\\tau)}}$$\n",
    "\n",
    "<img src=\"https://dt5vp8kor0orz.cloudfront.net/5fedcaeba7180898deb71d026db359b0a56af6b3/9-Figure4-1.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "arCQ_B06t_Yk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def equilibrium_k_means(X, k, alpha, n_iter):\n",
    "    centroids = initialize_centroids(X, k) # Initialize centroids\n",
    "    for _ in range(n_iter):\n",
    "        weights = Eq38_compute_weights(X, centroids, alpha)  # Compute weights\n",
    "        centroids = Eq39_update_centroids(X, weights)    # Update centroids\n",
    "    return centroids\n",
    "\n",
    "def initialize_centroids(X, k):\n",
    "    # Initialize centroids as random samples\n",
    "    return X[np.random.choice(X.shape[0], k, replace=False)]\n",
    "\n",
    "def Eq38_compute_weights(X, centroids, alpha):\n",
    "    #==== TODO: Compute the weights for each data point (refer to Eq. 38) ====#\n",
    "\n",
    "\n",
    "\n",
    "    #=========================================================================#\n",
    "    return weights\n",
    "\n",
    "def Eq39_update_centroids(X, weights):\n",
    "    #==== TODO: Update the centroids (refer to Eq. 39) ====#\n",
    "\n",
    "\n",
    "    #======================================================#\n",
    "    return centroids\n",
    "\n",
    "def select_clusters(weights):\n",
    "    return np.argmax(weights, axis=1)\n",
    "\n",
    "def plot_clusters(X, centroids, clustering, title='Equilibrium K-Means Clustering'):\n",
    "    plt.scatter(X[:,0], X[:,1], c=clustering, cmap='viridis')\n",
    "    plt.scatter(centroids[:,0], centroids[:,1], c='red', marker='x')\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "'''\n",
    "X1 = np.random.rand(100, 2) + np.array([[0.2,0.2]])\n",
    "X2 = np.random.rand(20, 2) + np.array([[0.2,1.6]])\n",
    "X3 = np.random.rand(80, 2) + np.array([[2.0,0.5]])\n",
    "X = np.concatenate([X1, X2, X3])\n",
    "\n",
    "k = 3  # Number of clusters\n",
    "alpha = 10  # Smoothing parameter\n",
    "n_iter = 50  # Number of iterations\n",
    "\n",
    "centroids = equilibrium_k_means(X, k, alpha, n_iter)\n",
    "print(\"Final centroids:\\n\", centroids)\n",
    "print(\"Real centroids:\\n\", np.array([np.mean(X1, axis=0), np.mean(X2, axis=0), np.mean(X3, axis=0)]))\n",
    "\n",
    "# Visualize the clustering - show the data points and the centroids\n",
    "clustering = select_clusters(Eq38_compute_weights(X, centroids, alpha))\n",
    "plot_clusters(X, centroids, clustering)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ohi17MWit_Yj"
   },
   "source": [
    "### t-SNE\n",
    "<span style=\"color:orange\">(TODO: Implement t-SNE)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkVfADvFt_Yj"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import manifold\n",
    "\n",
    "def prune_dimension(X):\n",
    "    # args: X (n_samples, dim)\n",
    "    # ouput: Y (n_samples, 2)\n",
    "    # TODO: implement t-SNE\n",
    "\n",
    "    return X[:, :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Oik19Ovt_Yl"
   },
   "source": [
    "### Demo with validation set\n",
    "This section demonstrate the functionality of t-SNE and clustering with the finetuning validation set.\n",
    " - Use clustered label\n",
    " - Use ground truth label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZEovmJKVRTf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate X, label\n",
    "X, label = [], []\n",
    "with torch.no_grad():\n",
    "    for img, lab in finetune_valid_dataset:\n",
    "        _, probs, latent_embedding = model(img.unsqueeze(0).to(finetune_config.device))\n",
    "        X.append(latent_embedding.cpu().numpy())\n",
    "        label.append(lab)\n",
    "X, label = np.concatenate(X), np.array(label)\n",
    "\n",
    "# consider three classes\n",
    "cls1, cls2, cls3 = 2, 5, 8\n",
    "cls_idx = np.where((label==cls1) | (label==cls2) | (label==cls3))\n",
    "X = X[cls_idx]\n",
    "label = label[cls_idx]\n",
    "\n",
    "# Perform equilibrium k-means clustering\n",
    "k = 3\n",
    "alpha = 0.01\n",
    "n_iter = 50\n",
    "centroids = equilibrium_k_means(X, k, alpha, n_iter)\n",
    "clustering = select_clusters(Eq38_compute_weights(X, centroids, alpha))\n",
    "\n",
    "# t-SNE\n",
    "Y = prune_dimension(np.concatenate([X, centroids]))\n",
    "Y, centroids = Y[:-3], Y[-3:]\n",
    "\n",
    "# plot\n",
    "plot_clusters(Y, centroids, clustering)\n",
    "plot_clusters(Y, centroids, label, 'Labelled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoBtWdQPt_Yl"
   },
   "source": [
    "### Anomaly detection\n",
    "This section demonstrate the usage of autoencoders for anomaly detection.\n",
    "\n",
    "We use the autoencoder to reconstruct an image of an unseen class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LIDfnrP-r_ik"
   },
   "outputs": [],
   "source": [
    "# train on class 1 (cars)\n",
    "class1_dataset = ImageDataset(load_unlabelled('./data/dev/labelled/2/'))\n",
    "class1_loader = DataLoader(class1_dataset, batch_size=8, shuffle=True)\n",
    "model = Autoencoder()\n",
    "pretrain(model, class1_loader, None, Namespace(\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    lr = pretrain_config.lr,\n",
    "    weight_decay = 0,\n",
    "    noise_factor = 0,\n",
    "    pretrain_epochs = 50\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RXqSSkgjt_Yl"
   },
   "outputs": [],
   "source": [
    "# Use the anomaly dataset and the pre-trained model to generate latent embeddings\n",
    "anomaly_dataset = ImageDataset(load_unlabelled('data/anomoly'), tfm=T.Compose([\n",
    "    T.Grayscale(num_output_channels=3),  # Convert grayscale to RGB by adding channels\n",
    "    T.ToTensor()\n",
    "]))\n",
    "anomaly_loader = DataLoader(anomaly_dataset, batch_size=pretrain_config.batch_size, shuffle=False)\n",
    "\n",
    "# compare losses\n",
    "anomaly_loss = []\n",
    "with torch.no_grad():\n",
    "    for image in anomaly_loader:\n",
    "        image = image.to(pretrain_config.device)\n",
    "        recon, _, _ = model(image)\n",
    "        loss = nn.MSELoss()(recon, image)\n",
    "        anomaly_loss.append(loss.item())\n",
    "anomaly_loss = sum(anomaly_loss) / len(anomaly_loss)\n",
    "print('Anomaly loss:', anomaly_loss)\n",
    "\n",
    "class1_loss = []\n",
    "with torch.no_grad():\n",
    "    for image in class1_loader:\n",
    "        image = image.to(pretrain_config.device)\n",
    "        recon, _, _ = model(image)\n",
    "        loss = nn.MSELoss()(recon, image)\n",
    "        class1_loss.append(loss.item())\n",
    "class1_loss = sum(class1_loss) / len(class1_loss)\n",
    "print('Normal loss :', class1_loss)\n",
    "\n",
    "# Show\n",
    "# 1. a pair of reconstructed image and original image for the anomaly class\n",
    "# 2. a pair of reconstructed image and original image for the normal class\n",
    "idx1, idx2 = 42, 10\n",
    "image1, image2 = anomaly_dataset[idx1], class1_dataset[idx2]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    recon1 = model(image1.unsqueeze(0).to(pretrain_config.device))[0].cpu().numpy()\n",
    "    recon2 = model(image2.unsqueeze(0).to(pretrain_config.device))[0].cpu().numpy()\n",
    "\n",
    "# plot the 4 images\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10,10))\n",
    "axs[0, 0].imshow(image1.numpy().transpose((1, 2, 0)))\n",
    "axs[0, 0].set_title('Anomaly Image')\n",
    "axs[0, 1].imshow(recon1.squeeze().transpose((1, 2, 0)))\n",
    "axs[0, 1].set_title('Reconstructed Anomaly Image')\n",
    "axs[1, 0].imshow(image2.numpy().transpose((1, 2, 0)))\n",
    "axs[1, 0].set_title('Normal Image')\n",
    "axs[1, 1].imshow(recon2.squeeze().transpose((1, 2, 0)))\n",
    "axs[1, 1].set_title('Reconstructed Normal Image')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
